# -*- coding: utf-8 -*-
"""
Created on Sun Oct 23 16:38:35 2022

@author: 82108
"""

# 필요한 라이브러리 불러오기 
## 판다스
import pandas as pd 

## 워드클라우드 시각화 
import matplotlib.pyplot as plt

from matplotlib import font_manager, rc
font_name = font_manager.FontProperties(fname="c:/windows/fonts/malgun.ttf").get_name()
rc('font',family=font_name)

from wordcloud import WordCloud, STOPWORDS # 불용어 사전 

## 맞춤법을 위한 한스펠
!pip install git+https://github.com/ssut/py-hanspell.git
from hanspell import spell_checker

## KoNLPy
from konlpy.tag import Okt

okt = Okt()


import collections
import numpy as np
import pandas as pd
from pandas import Series,DataFrame
from sklearn.feature_extraction.text import CountVectorizer 
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from konlpy.tag import Okt
okt=Okt()

-------------------------------------
# 데이터 불러오기
df = pd.read_csv("c:/data/text_anal.csv",encoding='utf-8')
df_yuan = df.copy() # 원본 보존하기 

## 전처리
df['텍스트'] = df['텍스트'].str.upper() #모두 대문자로 변환 
df['텍스트'] = df['텍스트'].str.replace("[ㄱ-ㅎ,ㅏ-ㅣ]",'',regex=True) # 자음으로 된 것들 삭제하기 


## 맞춤법 검사 
'''
띄어쓰기와 맞춤법이 올바르지 않아 형태소 분석 시 어려움이 많았다
이를 위해 네이버 맞춤법 검사기 기반으로 개발 된 hanspell을 다운받아 사용하였다.
'''

spelled_sent = [] #맞춤법 검
checked_sent = [] #검사 된 텍스트만 꺼내오기

for i in df['텍스트']:
    spelled_sent.append(spell_checker.check(i))

for i in spelled_sent:
    checked_sent.append(i.checked)


df['맞춤법'] = checked_sent

## 데이터리안 맞춤법이 날라가서 다시 교정하기 
df['맞춤법'] = df['맞춤법'].str.replace("데이터 라이안",'데이터리안',regex=True) 
df['맞춤법'] = df['맞춤법'].str.replace("데이터 분석가",'데이터분석가',regex=True)
df['맞춤법'] = df['맞춤법'].str.replace("데이터 분석",'데이터분석',regex=True) 
df['맞춤법'] = df['맞춤법'].str.replace("매출 분석",'매출분석',regex=True) 


df.to_excel('c:/data/데이터리안_리뷰_최종.xlsx')
test = pd.read_excel('c:/data/데이터리안_리뷰_최종.xlsx',index=False)
test = test.drop(['Unnamed: 0'],axis=1)


def okt_pos(arg):
    token_corpus = []
    for i in okt.pos(arg):
        if i[1] in ['Noun','']:
            token_corpus.append(i[0])
    return set(token_corpus)

review_cv = CountVectorizer(stop_words = stopwords, tokenizer = okt_pos).fit(test['맞춤법'])
review_cv.get_feature_names()
review_cv_train = review_cv.transform(test['맞춤법'])
review_cv_train.toarray()

# 사용자 정의 함수 
pip install customized_konlpy

from konlpy.tag import Okt
from ckonlpy.tag import Twitter

twitter = Twitter()
twitter.add_dictionary('아이오아이', 'Noun')
twitter.add_dictionary('데이터리안', 'Noun')
twitter.add_dictionary('데이터분석가', 'Noun')
twitter.add_dictionary('데이터분석', 'Noun')
twitter.add_dictionary('매출분석', 'Noun')

def twitter_pos(arg):
    token_corpus = []
    for i in twitter.pos(arg):
        if i[1] in ['Noun','Adjective']:
            token_corpus.append(i[0])
    return set(token_corpus)

datarian = test.copy()
datarian.info()

text = ' '.join(test['찐맞춤법'])
text


------ 
text 빈도수 찾는 코드

tmp_list = []
for i in test['찐맞춤법']:
    tmp_list.append(i)

def twitter_pos(arg):
    for i in twitter.pos(arg):
        if i[1] in ['Noun','Adjective']:
            token_corpus.append(i[0])
            
txt = ' '.join(tmp_list)

token_ko = twitter_pos(txt)

result = []
for i in token_corpus:
    if i not in stopwords:
        result.append(i)



    
